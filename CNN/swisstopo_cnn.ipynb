{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "%matplotlib inline\n",
    "#matplotlib.get_backend()\n",
    "\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU installed - You are as slow as a High-End Windows PC\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"No GPU installed - You are as slow as a High-End Windows PC\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folders = False\n",
    "\n",
    "# Odrner f端r die Originaldaten\n",
    "original_dataset_dir = 'dataset/original_data'\n",
    "\n",
    "# Ordner f端r die Trainings, Validierungs und Testdaten\n",
    "base_dir = 'dataset/dataset'\n",
    "#os.mkdir(base_dir)\n",
    "\n",
    "#creates train-, validation- and test-folder\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "#os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "#os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#os.mkdir(test_dir)\n",
    "\n",
    "# creates a cat and a dog folder in the train folder\n",
    "train_y_dir = os.path.join(train_dir, 'y')\n",
    "#os.mkdir(train_y_dir)\n",
    "train_n_dir = os.path.join(train_dir, 'n')\n",
    "#os.mkdir(train_n_dir)\n",
    "\n",
    "# creates a cat and a dog folder in the validation folder\n",
    "validation_y_dir = os.path.join(validation_dir, 'y')\n",
    "#os.mkdir(validation_y_dir)\n",
    "validation_n_dir = os.path.join(validation_dir, 'n')\n",
    "#os.mkdir(validation_n_dir)\n",
    "\n",
    "# creates a cat and a dog folder in the test folder\n",
    "test_y_dir = os.path.join(test_dir, 'y')\n",
    "#os.mkdir(test_y_dir)\n",
    "test_n_dir = os.path.join(test_dir, 'n')\n",
    "#os.mkdir(test_n_dir)\n",
    "\n",
    "if new_folders == True:\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    os.mkdir(train_y_dir)\n",
    "    os.mkdir(train_n_dir)\n",
    "    os.mkdir(validation_y_dir)\n",
    "    os.mkdir(validation_n_dir)\n",
    "    os.mkdir(test_y_dir)\n",
    "    os.mkdir(test_n_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total y images: 172\n",
      "total n images: 246\n"
     ]
    }
   ],
   "source": [
    "# read size of the dataset folders\n",
    "\n",
    "print('total y images:', len(os.listdir('dataset/original_data/y')))\n",
    "print('total n images:', len(os.listdir('dataset/original_data/n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculates the number of images for train, validation and test\n",
    "train_size = 0.6\n",
    "validation_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "# calculates the number of images for train, validation and test\n",
    "train_y_size = int(len(os.listdir('dataset/original_data/y')) * train_size)\n",
    "train_n_size = int(len(os.listdir('dataset/original_data/n')) * train_size)\n",
    "\n",
    "validation_y_size = int(len(os.listdir('dataset/original_data/y')) * validation_size)\n",
    "validation_n_size = int(len(os.listdir('dataset/original_data/n')) * validation_size)\n",
    "\n",
    "test_y_size = int(len(os.listdir('dataset/original_data/y')) * test_size)\n",
    "test_n_size = int(len(os.listdir('dataset/original_data/n')) * test_size)\n",
    "\n",
    "train_y_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed = True\n",
    "y_dir = 'dataset/original_data/y/'\n",
    "n_dir = 'dataset/original_data/n/'\n",
    "if renamed == False:\n",
    "    # change name of the images in the dataset folder\n",
    "    # nur einmal Ausf端hren!\n",
    "\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for filename in os.listdir(y_dir):\n",
    "        os.rename(y_dir + filename, y_dir + 'y.' + str(i) + '.jpg')\n",
    "        i = i + 1\n",
    "\n",
    "    y = 0\n",
    "    for filename in os.listdir(n_dir):\n",
    "        os.rename(n_dir + filename, n_dir + 'n.' + str(y) + '.jpg')\n",
    "        y = y + 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train_y_size images from the original dataset to the train_y_dir\n",
    "fnames = ['y.{}.jpg'.format(i) for i in range(train_y_size)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(y_dir, fname)\n",
    "    dst = os.path.join(train_y_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# copy train_n_size images from the original dataset to the train_n_dir\n",
    "fnames = ['n.{}.jpg'.format(i) for i in range(train_n_size)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(n_dir, fname)\n",
    "    dst = os.path.join(train_n_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# copy validation_y_size images from the original dataset to the validation_y_dir\n",
    "fnames = ['y.{}.jpg'.format(i) for i in range(train_y_size, train_y_size + validation_y_size)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(y_dir, fname)\n",
    "    dst = os.path.join(validation_y_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# copy validation_n_size images from the original dataset to the validation_n_dir\n",
    "fnames = ['n.{}.jpg'.format(i) for i in range(train_n_size, train_n_size + validation_n_size)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(n_dir, fname)\n",
    "    dst = os.path.join(validation_n_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# copy test_y_size images from the original dataset to the test_y_dir\n",
    "fnames = ['y.{}.jpg'.format(i) for i in range(train_y_size + validation_y_size, train_y_size + validation_y_size + test_y_size)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(y_dir, fname)\n",
    "    dst = os.path.join(test_y_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# copy test_n_size images from the original dataset to the test_n_dir\n",
    "fnames = ['n.{}.jpg'.format(i) for i in range(train_n_size + validation_n_size, train_n_size + validation_n_size + test_n_size)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(n_dir, fname)\n",
    "    dst = os.path.join(test_n_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training y images: 103\n",
      "total training n images: 147\n",
      "total validation y images: 51\n",
      "total validation n images: 70\n",
      "total test y images: 51\n",
      "total test n images: 70\n"
     ]
    }
   ],
   "source": [
    "print('total training y images:', len(os.listdir(train_y_dir)))\n",
    "print('total training n images:', len(os.listdir(train_n_dir)))\n",
    "print('total validation y images:', len(os.listdir(validation_y_dir)))\n",
    "print('total validation n images:', len(os.listdir(validation_n_dir)))\n",
    "print('total test y images:', len(os.listdir(test_y_dir)))\n",
    "print('total test n images:', len(os.listdir(test_n_dir)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering with Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 250 images belonging to 2 classes.\n",
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# without Data Augmentation\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,)\n",
    "\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the output of one of these generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor data_batch, labels_batch in train_generator:\\n    print('data_batch shape:', data_batch.shape)\\n    print('labels batch shape', labels_batch.shape)\\n    break\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data_batch shape:', data_batch.shape)\n",
    "    print('labels batch shape', labels_batch.shape)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Nun sollen Sie ein Modell f端r diese Daten bauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 64)      1792      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 148, 148, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 146, 146, 32)      18464     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 146, 146, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 73, 73, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 170528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               21827712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,848,097\n",
      "Trainable params: 21,848,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create a base_line model\n",
    "\n",
    "base_model = keras.models.Sequential()\n",
    "\n",
    "base_model.add(keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "base_model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "base_model.add(keras.layers.Dropout(0.5))\n",
    "base_model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#regularization\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_model.add(tf.keras.layers.Flatten())\n",
    "base_model.add(keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "base_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "base_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benit\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\benit\\AppData\\Local\\Temp\\ipykernel_9540\\2581788618.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = base_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25/25 [==============================] - 22s 834ms/step - loss: 8.9488 - acc: 0.5440 - val_loss: 0.6939 - val_acc: 0.4215\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 18s 744ms/step - loss: 0.6852 - acc: 0.6160 - val_loss: 0.6938 - val_acc: 0.4215\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 17s 705ms/step - loss: 0.6506 - acc: 0.6480 - val_loss: 0.6949 - val_acc: 0.4215\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 18s 714ms/step - loss: 1.2249 - acc: 0.6480 - val_loss: 0.6925 - val_acc: 0.3967\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 19s 769ms/step - loss: 0.7256 - acc: 0.6960 - val_loss: 0.6863 - val_acc: 0.8678\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 19s 763ms/step - loss: 0.8019 - acc: 0.7280 - val_loss: 0.6777 - val_acc: 0.8430\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 19s 773ms/step - loss: 0.5024 - acc: 0.8160 - val_loss: 0.6274 - val_acc: 0.8512\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.5019 - acc: 0.7760 - val_loss: 0.6341 - val_acc: 0.8678\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 17s 701ms/step - loss: 0.5821 - acc: 0.8160 - val_loss: 0.5164 - val_acc: 0.8017\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 17s 708ms/step - loss: 0.4172 - acc: 0.8160 - val_loss: 0.5386 - val_acc: 0.8760\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 19s 755ms/step - loss: 0.3780 - acc: 0.8480 - val_loss: 0.5220 - val_acc: 0.8678\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 20s 818ms/step - loss: 0.4156 - acc: 0.8560 - val_loss: 0.5689 - val_acc: 0.8430\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 19s 759ms/step - loss: 0.1885 - acc: 0.9280 - val_loss: 0.6317 - val_acc: 0.7355\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 19s 763ms/step - loss: 0.4260 - acc: 0.9280 - val_loss: 0.5085 - val_acc: 0.8760\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 18s 747ms/step - loss: 0.1527 - acc: 0.9360 - val_loss: 0.6723 - val_acc: 0.8099\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 19s 755ms/step - loss: 0.1427 - acc: 0.9360 - val_loss: 0.5561 - val_acc: 0.8678\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 19s 752ms/step - loss: 0.1675 - acc: 0.9440 - val_loss: 0.5223 - val_acc: 0.8595\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 19s 765ms/step - loss: 0.1130 - acc: 0.9600 - val_loss: 0.5943 - val_acc: 0.8595\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 19s 767ms/step - loss: 0.2217 - acc: 0.9360 - val_loss: 0.5167 - val_acc: 0.8595\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 19s 753ms/step - loss: 0.0749 - acc: 0.9920 - val_loss: 1.2387 - val_acc: 0.7355\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 19s 752ms/step - loss: 0.2502 - acc: 0.9680 - val_loss: 0.4998 - val_acc: 0.8760\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 19s 758ms/step - loss: 0.5390 - acc: 0.9520 - val_loss: 0.6908 - val_acc: 0.8264\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 19s 756ms/step - loss: 0.1506 - acc: 0.9840 - val_loss: 0.5055 - val_acc: 0.8678\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 18s 743ms/step - loss: 0.0668 - acc: 0.9920 - val_loss: 0.5825 - val_acc: 0.8430\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 19s 756ms/step - loss: 0.2405 - acc: 0.9600 - val_loss: 0.5005 - val_acc: 0.8760\n"
     ]
    }
   ],
   "source": [
    "base_model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.RMSprop(lr=1e-3), metrics=['acc'])\n",
    "\n",
    "history = base_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 25,\n",
    "    epochs = 25,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Assuming you have defined the variables 'acc' and 'val_acc'\n",
    "#title\n",
    "fig.update_layout(\n",
    "    title=\"Base Model\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, len(acc)+1), y=acc,\n",
    "                    mode='lines',\n",
    "                    name='accuracy'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, len(val_acc)+1), y=val_acc,\n",
    "                    mode='lines',\n",
    "                    name='validation accuracy'))\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "pio.write_html(fig, 'base_model.html')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrainned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benit\\AppData\\Local\\Temp\\ipykernel_9540\\217282344.py:19: UserWarning:\n",
      "\n",
      "`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "25/25 [==============================] - 21s 790ms/step - loss: 0.5935 - acc: 0.7680 - val_loss: 0.5792 - val_acc: 0.7769\n",
      "Epoch 2/15\n",
      "25/25 [==============================] - 19s 776ms/step - loss: 0.5212 - acc: 0.8480 - val_loss: 0.5493 - val_acc: 0.7934\n",
      "Epoch 3/15\n",
      "25/25 [==============================] - 19s 753ms/step - loss: 0.4907 - acc: 0.8640 - val_loss: 0.5246 - val_acc: 0.7769\n",
      "Epoch 4/15\n",
      "25/25 [==============================] - 19s 760ms/step - loss: 0.4610 - acc: 0.8400 - val_loss: 0.5060 - val_acc: 0.7603\n",
      "Epoch 5/15\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.4251 - acc: 0.8720 - val_loss: 0.5051 - val_acc: 0.7521\n",
      "Epoch 6/15\n",
      "25/25 [==============================] - 29s 1s/step - loss: 0.4345 - acc: 0.8400 - val_loss: 0.4930 - val_acc: 0.7521\n",
      "Epoch 7/15\n",
      "25/25 [==============================] - 20s 788ms/step - loss: 0.3825 - acc: 0.8720 - val_loss: 0.4778 - val_acc: 0.7521\n",
      "Epoch 8/15\n",
      "25/25 [==============================] - 19s 754ms/step - loss: 0.4162 - acc: 0.8240 - val_loss: 0.4829 - val_acc: 0.7603\n",
      "Epoch 9/15\n",
      "25/25 [==============================] - 19s 760ms/step - loss: 0.3707 - acc: 0.8800 - val_loss: 0.4713 - val_acc: 0.7521\n",
      "Epoch 10/15\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 0.3355 - acc: 0.8800 - val_loss: 0.4760 - val_acc: 0.7686\n",
      "Epoch 11/15\n",
      "25/25 [==============================] - 22s 874ms/step - loss: 0.3405 - acc: 0.8720 - val_loss: 0.4746 - val_acc: 0.7686\n",
      "Epoch 12/15\n",
      "25/25 [==============================] - 21s 844ms/step - loss: 0.3657 - acc: 0.8560 - val_loss: 0.4918 - val_acc: 0.7686\n",
      "Epoch 13/15\n",
      "25/25 [==============================] - 21s 831ms/step - loss: 0.3312 - acc: 0.8720 - val_loss: 0.4984 - val_acc: 0.7769\n",
      "Epoch 14/15\n",
      "25/25 [==============================] - 23s 952ms/step - loss: 0.3010 - acc: 0.8800 - val_loss: 0.4742 - val_acc: 0.7686\n",
      "Epoch 15/15\n",
      "25/25 [==============================] - 33s 1s/step - loss: 0.3296 - acc: 0.8800 - val_loss: 0.4766 - val_acc: 0.7686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load pre-trained VGG16 model without the top layers (include_top=False)\n",
    "pr_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the pre-trained layers to prevent them from being updated during training\n",
    "pr_model.trainable = False\n",
    "\n",
    "# Create a new model by adding your own classifier on top of the pre-trained base\n",
    "model = keras.models.Sequential()\n",
    "model.add(pr_model)\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history1 = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=25,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=25\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history1.history['acc']\n",
    "val_acc = history1.history['val_acc']\n",
    "loss = history1.history['loss']\n",
    "val_loss = history1.history['val_loss']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Assuming you have defined the variables 'acc' and 'val_acc'\n",
    "\n",
    "#title\n",
    "fig.update_layout(\n",
    "    title=\"Pretrained Model\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, len(acc)+1), y=acc,\n",
    "                    mode='lines',\n",
    "                    name='accuracy'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, len(val_acc)+1), y=val_acc,\n",
    "                    mode='lines',\n",
    "                    name='validation accuracy'))\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "pio.write_html(fig, 'pretrained_model.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# 1st convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# 2nd convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# 3rd convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# FFNN\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 148, 148, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 74, 74, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 72, 72, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 36, 36, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 34, 34, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 17, 17, 128)       0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 36992)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               18940416  \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,037,121\n",
      "Trainable params: 19,035,649\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 [==============================] - 35s 661ms/step - loss: 0.9089 - accuracy: 0.7200 - val_loss: 0.8924 - val_accuracy: 0.5785\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 28s 569ms/step - loss: 0.6218 - accuracy: 0.7760 - val_loss: 1.6174 - val_accuracy: 0.5785\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 28s 570ms/step - loss: 0.5760 - accuracy: 0.8000 - val_loss: 2.2947 - val_accuracy: 0.5785\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 29s 574ms/step - loss: 0.4482 - accuracy: 0.8360 - val_loss: 3.3709 - val_accuracy: 0.5785\n",
      "Epoch 5/15\n",
      "49/50 [============================>.] - ETA: 0s - loss: 0.4064 - accuracy: 0.8449"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_generator, epochs=15, validation_data=validation_generator, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m sns\u001b[39m.\u001b[39mset_style(\u001b[39m\"\u001b[39m\u001b[39mdarkgrid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      6\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel 4 Training and Validation Accuracy 6000 Images with Data Augmentation and Batch Normalization\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Assuming you have defined the variables 'acc' and 'val_acc'\n",
    "\n",
    "#title\n",
    "fig.update_layout(\n",
    "    title=\"CNN Model\",\n",
    "    xaxis_title=\"Epochs\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, len(acc)+1), y=acc,\n",
    "                    mode='lines',\n",
    "                    name='accuracy'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, len(val_acc)+1), y=val_acc,\n",
    "                    mode='lines',\n",
    "                    name='validation accuracy'))\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "pio.write_html(fig, 'C_D_model.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 358 images belonging to 2 classes.\n",
      "18/18 [==============================] - 11s 615ms/step - loss: 1.1475 - accuracy: 0.7207\n",
      "test acc: 0.7206704020500183\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('test acc:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
